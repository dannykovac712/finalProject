<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Structured Theorem Extraction </title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 900px;
      margin: 0 auto;
      padding: 20px;
      line-height: 1.6;
    }
    header, section {
      margin-bottom: 2rem;
    }
    h1, h2, h3 {
      margin-bottom: 0.4rem;
    }
    .teammates li {
      margin-bottom: 0.2rem;
    }
    .video-container {
      position: relative;
      padding-bottom: 56.25%;
      height: 0;
      overflow: hidden;
      max-width: 100%;
    }
    .video-container iframe {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      border: 0;
    }
    .footer {
      margin-top: 3rem;
      font-size: 0.9rem;
      color: #555;
    }
    a {
      text-decoration: none;
    }
  </style>
</head>
<body>
  <header>
    <h1>Structured Theorem Extraction</h1>
    <p><strong>Course:</strong> Select Topics in Math / (01:640:495) Section 03</p>
  </header>

  <section id="overview">
    <h2>Overview & Motivation</h2>
    <p>
      Modern mathematical writing—especially on platforms like arXiv—contains thousands
      of new theorems each year. These theorems are typically written for human readers as
      a mix of natural language and LaTeX, which makes them hard to search, index, or reuse
      automatically.
    </p>
    <p>
      This project explores how to convert raw theorem statements into a machine-readable
      representation. The goal is to take a single theorem written in natural language and
      produce a structured JSON object that separates the type of result (e.g., theorem, lemma),
      its assumptions, and its conclusion. The focus is on capturing the main components of
      a claim in a consistent way, not on formalizing proofs.
    </p>
  </section>

  <section id="methodology">
    <h2>Methodology</h2>
    <p>
      The system is built on top of the Mistral-7B-Instruct-v0.2 model, chosen for its
      instruction-following behavior, open weights, and solid reasoning performance
      relative to its size. The model is adapted with QLoRA, which learns small adapter
      weights while keeping the base model frozen. This keeps memory usage low and makes
      training feasible on limited hardware.
    </p>
    <p>
      The dataset consists of about 300 theorem-like statements paired with JSON
      annotations. Each example follows a fixed schema with fields such as
      <code>type</code>, <code>id</code>, <code>name</code>, a list of
      <code>assumptions</code>, and a single <code>conclusion</code>. Theorems were
      collected via the OpenAI API from a range of mathematical topics, with an emphasis
      on clean statements where assumptions and conclusions can be separated.
    </p>
    <p>
      Prompts use a consistent format: an instruction header describing the expected
      JSON fields, the theorem text, and explicit <code>&lt;json&gt;</code> delimiters.
      Training uses a standard causal language modeling objective, but loss is applied
      only to the JSON portion of the output (prompt tokens are excluded). This encourages
      the model to focus on generating well-formed structured outputs.
    </p>
    <p>
      At inference time, the base model is loaded once and the QLoRA adapters are applied
      on top. New theorem statements are wrapped in the same prompt template, the model
      generates a response, and the first JSON block between the delimiters is extracted
      as the final structured theorem representation.
    </p>
  </section>

  <section id="results">
    <h2>Results & Findings</h2>
    <p>
      Evaluation is mainly qualitative. Because a single theorem can be parsed in several
      reasonable ways, a strict automatic metric is hard to define. Instead, outputs are
      inspected by hand to see whether the assumptions and conclusion are separated in a
      sensible way and whether the JSON matches the intended schema.
    </p>
    <p>
      For many short or moderately complex theorems, the model produces clear JSON:
      assumptions are listed as separate bullet-like strings and the conclusion is captured
      as a single statement. In these cases, the structure aligns well with what a human
      reader would identify as “conditions” versus “main claim.”
    </p>
    <p>
      When the model fails, several patterns appear. Sometimes it generates more than one
      JSON object in a single response, or adds extra conclusions that go beyond the
      original theorem. Formatting issues (for example, missing delimiters or truncated
      fields) also show up more often as the input theorems become longer or pack many
      assumptions and conclusions into a single sentence.
    </p>
  </section>

  <section id="drawbacks">
    <h2>Limitations & Future Work</h2>
    <p>
      There are three main types of limitations. First, hardware and data scale are
      constrained. Training was done on limited compute, so the model could not be trained
      for as long or on as large a dataset as desired. This limits how much the system can
      improve through fine-tuning.
    </p>
    <p>
      Second, the model is designed to handle one theorem at a time. It does not track
      references to earlier results, long chains of context, or multiple theorems in a
      single prompt. This makes it better suited for standalone statements than for
      entire sections of a paper.
    </p>
    <p>
      Finally, the largest limitation comes from mathematical language itself. Theorems
      often contain implicit assumptions or rely on shared background that is not written
      explicitly. Different readers may disagree about what counts as an assumption versus
      what belongs in the conclusion, and there is no fully objective way to check whether
      a JSON parse is “correct.” The output should therefore be seen as a reasonable
      interpretation, not a guaranteed ground truth.
    </p>
    <p>
      Future work could address these issues by expanding the dataset to cover more areas
      and writing styles, using schema-based decoding to enforce valid JSON, and
      integrating the structured representations with other tools such as proof assistants
      or dependency-tracking systems.
    </p>
  </section>

  <section id="author">
    <h2>Author</h2>
      <li><strong>Danny Kovac</strong> – dk1123@scarletmail.rutgers.edu</li>
  </section>

  <section id="repo">
    <h2>Project Repository</h2>
    <p>
      All source code and the full report are available on GitHub:
      <br />
      <a
        href="https://drive.google.com/file/d/1vzCq00wIJ3StBckpkk5wRwpD3NqcPaeg/view?usp=sharing"
        target="_blank"
        rel="noopener noreferrer">
        Watch Presentation on Google Drive
      </a>
    </p>
    <p>
      You can download the full 15-page report here:
      <br />
      <a href="Math AI Final Project (1).pdf" target="_blank">Download Project Report (PDF)</a>
      <!-- Make sure this filename matches the actual PDF in your repo -->
    </p>
  </section>

  <section id="video">
  <h2>Project Talk</h2>
    <p>
  <a href="495FinalAIProject.mp4" target="_blank">
    Click to Watch the project presentation
  </a>
</p>
</section>


  <section id="comments">
    <h2>Comments & Feedback</h2>

    <h3>Option 1: Email</h3>
    <p>
      You can send feedback on this google form:
      <br />
      <a href="https://docs.google.com/forms/d/e/1FAIpQLSfs5DFqLxb-G8aeMvWVQqFmzRLB-osOBmYxw5vz76iyHMiGdg/viewform?usp=sharing&ouid=105823594247858959740">
        Feedback Form
      </a>
    </p>
  </section>

  <div class="footer">
    <p>Last updated: December 9, 2025</p>
  </div>
</body>
</html>
